---
title: 数字图形设计常见五个算法
date: 2023-06-15
categories: 
- 数字图形设计
tags:
- 数字图形设计
---
数字图形设计常见五个算法
数字图形设计常见五个算法

<!-- more -->

### KNN最近邻算法

**有标签**的**分类**算法

比如对电影分类

> 算法输入:  **待分类**的样本,**有标签**的数据
>
> 算法过程:   
>
> > 1. 备数据并对数据进行预处理
> > 2. 计算待分类样本到数据集中每个样本的相似度
> > 3. 对相似度结果由高到低**进行排序**
> > 4. 计算K个**最高值各类**所占的比例
> > 5. 取所占比例最高来的标签,并将标签打到样本上
>
> 算法输出:  已经**打好标签**的样本

详细说明:

有三个豆是未知的种类，如何判定他们的种类

思路一：未知的豆离 哪种豆最近就认为未知豆和该豆是同一 种类。由此，我们引出最近邻算法的定 义：为了判定未知样本的类别，以全部训练样本作为代表点，计算未知样本与 所有训练样本的距离，并以最近邻者的 类别作为决策未知样本类别的唯一依据。 但是，最近邻算法明显是存在缺陷的

KNN算法的实现步骤:

1. step.1---初始化距离为最大值 
2. step.2---计算未知样本和每个训练样本的距离dist 
3. step.3---得到目前K个最临近样本中的最大距离maxdist 
4. step.4---如果dist小于maxdist，则将该训练样本作为K-最近 邻样本 
5. step.5---重复步骤2、3、4，直到未知样本和所有训练样本的 距离都算完 
6. step.6---统计K个最近邻样本中每个类别出现的次数 
7. step.7---选择出现频率最大的类别作为未知样本的类别

KNN缺点

该算法在分类时有个重要的 不足是，当样本不平衡时，即：一个类的样本容量很大， 而其他类样本数量很小时，很有可能导致当输入一个未 知样本时，该样本的K个邻居中大数量类的样本占多数。 但是这类样本并不接近目标样本，而数量小的这类样本 很靠近目标样本。这个时候，我们有理由认为该位置样 本属于数量小的样本所属的一类，但是，KNN却不关心 这个问题，它只关心哪类样本的数量最多，而不去把距 离远近考虑在内，因此，我们可以采用权值的方法来改 进。和该样本距离小的邻居权值大，和该样本距离大的 邻居权值则相对较小，由此，将距离远近的因素也考虑 在内，避免因一个样本过大导致误判的情况。



### K-means聚类算法

K-means算法是很典型的基于距离的聚 类算法，采用距离作为相似性的评价指标， 即认为两个对象的距离越近，其相似度就 越大。 该算法认为类是由距离靠近的对象组成 的，因此把得到紧凑且独立的类作为最终 目标

**无标签**、**无监督**的聚类算法

> 算法输入: 待分类的数据集合
>
> 算法过程: 
>
> > 1. **随机**取**K个**样本作为**聚类中心**
> > 2. 将数据样本集合中的样本按照最小距离原则分配到最邻近聚类
> > 3. 根据聚类的结果,重新计算K个聚类的中心,并作为新的聚类中心
> > 4. **重复**执行2和3, 直到聚类中心**不再变化**
>
> 算法输出:  已经分为K个簇的数据

详细说明:

K-means算法是很典型的基于距离的聚 类算法，采用距离作为相似性的评价指标， 即认为两个对象的距离越近，其相似度就 越大。该算法认为类是由距离靠近的对象组成 的，因此把得到紧凑且独立的类作为最终 目标。

算法过程:

1. 随机选取K个对象作为初始聚类中心；
2. 将数据样本集合中的样本按照最小距离 原则分配到最邻近聚类；
3. 根据聚类的结果，重新计算K个聚类的 中心，并作为新的聚类中心；
4. 重复步骤2.3直到聚类中心不再变化

K-means 缺点:

1. 要求必须事先给出要生成的类的数 目k，这个k值的选定是非常难以估计。
2. 对初值敏感，对于不同的初始值， 可能会导致不同的聚类结果。
3. 对于"噪声"和孤立点数据敏感，少量的该类数据能够对平均值产生极大影响

### 最小二乘算法

解决回归问题

### 卷积conv

卷积(Convolution)

算法思想: 从底层的Features向高层次的Features转化,以达到抽象描述的能力

> 算法输入: 样本数据(特征值, 标签)
>
> 算法过程: 
>
> > 1. 定义卷积核的size和初始值
> > 2. 指定步长 stride
> > 3. 基于实际情况判定是否用padding
> > 4. 特征提取: 利用卷积核对Features进行计算处理,得到最新的Features
> > 5. 卷积后还可进行池化,( Max padding, Avg padding ),(池化会使特征丢失),这步可迭代
>
> 算法输出:  卷积后的Features



### SVM支持向量

SVM(Support Vector Machine)中文名为支持向量，是常见的一种判别方法

算法思想: 在低纬线性不可分的情况下,转化到高纬,在高纬空间寻找超平面,使样本可分类

> 算法输入:  样本数据集
>
> 算法过程:  
>
> > 1. 确定平面的法向量
> >
> >    ```wiki
> >    w^*x + b^* = 0
> >    ```
> >
> > 2. 求点到面的距离(所有点)
> >    ```wiki
> >    |WTx + b|  / |Wt| 转化为 min|W|^2 , 将margin最大化转为L2 min |W|^2
> >    ```
> >
> > 3. 具体可采用梯度下降算法实现Ada
>
> 算法输出: 找到参数wb确定超平面,对数据进行分类






### 底部

没有了























